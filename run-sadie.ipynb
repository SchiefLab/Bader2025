{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6032acab",
   "metadata": {},
   "source": [
    "# Installation of required packages\n",
    "```bash\n",
    "conda create -n sadie python=3.10.5 pip\n",
    "pip install sadie-antibody\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4e1687-7336-4a95-aac6-0f94d217c795",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6143a99a-66b4-45fc-81ca-2cbd01f978e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in Python\n",
    "from pathlib import Path\n",
    "\n",
    "# Third Part Libraries\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from sadie.airr import Airr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc4c0c",
   "metadata": {},
   "source": [
    "# Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb0eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id_heavy</th>\n",
       "      <th>sequence_id_light</th>\n",
       "      <th>sequence_heavy</th>\n",
       "      <th>sequence_light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000b62-d08f-4917-adf4-905941f380cc</td>\n",
       "      <td>00000b62-d08f-4917-adf4-905941f380cc</td>\n",
       "      <td>TACGTTGCGAACACCTACTACAATCCGTCCCTCAAGAGTCGAGTCT...</td>\n",
       "      <td>ACCGGCAGAAACCTGGCCAGGCTCCCAGGCTCCTCATTTATGGTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00005592-a265-4e78-b1de-d105668dadce</td>\n",
       "      <td>00005592-a265-4e78-b1de-d105668dadce</td>\n",
       "      <td>GCAGTAGTGGCACTACGAAGTTCTACTCAGAATCTCTGAGGGGCCG...</td>\n",
       "      <td>GGTGCATCCATTCTACACAGTGGAGTCCCATCAAGGTTCAGTGGCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00008ba7-06e0-417a-b918-d42dbc6fc90c</td>\n",
       "      <td>00008ba7-06e0-417a-b918-d42dbc6fc90c</td>\n",
       "      <td>CAGTTATGTCGTCTGATGGCAGTGAGACATACTTTGCAGACTCCGT...</td>\n",
       "      <td>CGCACGCTCATCTACGCCACAAGTGCTCGCTTTTCTGGGGTCCCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00010dc3-7723-4b3d-9453-7e1406e84c70</td>\n",
       "      <td>00010dc3-7723-4b3d-9453-7e1406e84c70</td>\n",
       "      <td>ACTGGGCAAGGGTTTGAGTGGATGGGATGGATGAACCCTAACACTG...</td>\n",
       "      <td>TCCCCTGTGTTGGTCATCTATCAAGATGCCAAGCGGCCCTCAGGGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001417a-1b6c-4a43-acfb-c2c0283f73ce</td>\n",
       "      <td>0001417a-1b6c-4a43-acfb-c2c0283f73ce</td>\n",
       "      <td>CCAGAGACAATTCCAAGAACACGCTGCATTTGCAAATGACCAGCCT...</td>\n",
       "      <td>GGTACCAGCACAAACCTGGCCAGGCTCCCAGGCTCCTCGTCTATGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67988</th>\n",
       "      <td>fff17e16-46e2-49b5-966c-f41ffdd7509e</td>\n",
       "      <td>fff17e16-46e2-49b5-966c-f41ffdd7509e</td>\n",
       "      <td>CTCACCATCTCCAAGGACACCTCCAAAACCCAGGTGGTCCTTACAA...</td>\n",
       "      <td>ACTGTGATCTATGAGGATGATCACAGACCCTCTGGGGTCCCTGATC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67989</th>\n",
       "      <td>fff4650e-83c7-4320-bdf5-48f8e5c6dd4b</td>\n",
       "      <td>fff4650e-83c7-4320-bdf5-48f8e5c6dd4b</td>\n",
       "      <td>AGAAGTTCCAGGGCAGAGTCACCATGACCGAGGACATATCTACAGA...</td>\n",
       "      <td>GTCATCTATTATGATAGCGACCGACCCTCAGGGATCCCTGAGCGAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67990</th>\n",
       "      <td>fff4dd7d-f140-4618-9006-131149021a9a</td>\n",
       "      <td>fff4dd7d-f140-4618-9006-131149021a9a</td>\n",
       "      <td>GACAGAGTCACCATGGCCAGGGACACGTCCACGAGCACAGCCTACA...</td>\n",
       "      <td>AGAAACCAGGGAAACCCCCTAAGCTCCTGATCTACGATGCATCCAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67991</th>\n",
       "      <td>fffac9d8-b7e0-4b68-a6ab-07e532ab1219</td>\n",
       "      <td>fffac9d8-b7e0-4b68-a6ab-07e532ab1219</td>\n",
       "      <td>AAGTGATAAATACTATGCAGACTCCGTGAAGGGCCGATTCACCATC...</td>\n",
       "      <td>ACCGGCAGAAACCGGGACAGCCTCCTAAGCTGCTCATTTACTGGGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67992</th>\n",
       "      <td>fffd3c8a-5bcd-402e-8058-03b484e35bd4</td>\n",
       "      <td>fffd3c8a-5bcd-402e-8058-03b484e35bd4</td>\n",
       "      <td>CGGATTCATCATCTCAAGAGATGATTCCAAAGGCATCGCCTATCTG...</td>\n",
       "      <td>CACTGTGATCTATGAGGATAAGCAAAGACCCTCTGGGGTCCCTGAT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67993 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sequence_id_heavy  \\\n",
       "0      00000b62-d08f-4917-adf4-905941f380cc   \n",
       "1      00005592-a265-4e78-b1de-d105668dadce   \n",
       "2      00008ba7-06e0-417a-b918-d42dbc6fc90c   \n",
       "3      00010dc3-7723-4b3d-9453-7e1406e84c70   \n",
       "4      0001417a-1b6c-4a43-acfb-c2c0283f73ce   \n",
       "...                                     ...   \n",
       "67988  fff17e16-46e2-49b5-966c-f41ffdd7509e   \n",
       "67989  fff4650e-83c7-4320-bdf5-48f8e5c6dd4b   \n",
       "67990  fff4dd7d-f140-4618-9006-131149021a9a   \n",
       "67991  fffac9d8-b7e0-4b68-a6ab-07e532ab1219   \n",
       "67992  fffd3c8a-5bcd-402e-8058-03b484e35bd4   \n",
       "\n",
       "                          sequence_id_light  \\\n",
       "0      00000b62-d08f-4917-adf4-905941f380cc   \n",
       "1      00005592-a265-4e78-b1de-d105668dadce   \n",
       "2      00008ba7-06e0-417a-b918-d42dbc6fc90c   \n",
       "3      00010dc3-7723-4b3d-9453-7e1406e84c70   \n",
       "4      0001417a-1b6c-4a43-acfb-c2c0283f73ce   \n",
       "...                                     ...   \n",
       "67988  fff17e16-46e2-49b5-966c-f41ffdd7509e   \n",
       "67989  fff4650e-83c7-4320-bdf5-48f8e5c6dd4b   \n",
       "67990  fff4dd7d-f140-4618-9006-131149021a9a   \n",
       "67991  fffac9d8-b7e0-4b68-a6ab-07e532ab1219   \n",
       "67992  fffd3c8a-5bcd-402e-8058-03b484e35bd4   \n",
       "\n",
       "                                          sequence_heavy  \\\n",
       "0      TACGTTGCGAACACCTACTACAATCCGTCCCTCAAGAGTCGAGTCT...   \n",
       "1      GCAGTAGTGGCACTACGAAGTTCTACTCAGAATCTCTGAGGGGCCG...   \n",
       "2      CAGTTATGTCGTCTGATGGCAGTGAGACATACTTTGCAGACTCCGT...   \n",
       "3      ACTGGGCAAGGGTTTGAGTGGATGGGATGGATGAACCCTAACACTG...   \n",
       "4      CCAGAGACAATTCCAAGAACACGCTGCATTTGCAAATGACCAGCCT...   \n",
       "...                                                  ...   \n",
       "67988  CTCACCATCTCCAAGGACACCTCCAAAACCCAGGTGGTCCTTACAA...   \n",
       "67989  AGAAGTTCCAGGGCAGAGTCACCATGACCGAGGACATATCTACAGA...   \n",
       "67990  GACAGAGTCACCATGGCCAGGGACACGTCCACGAGCACAGCCTACA...   \n",
       "67991  AAGTGATAAATACTATGCAGACTCCGTGAAGGGCCGATTCACCATC...   \n",
       "67992  CGGATTCATCATCTCAAGAGATGATTCCAAAGGCATCGCCTATCTG...   \n",
       "\n",
       "                                          sequence_light  \n",
       "0      ACCGGCAGAAACCTGGCCAGGCTCCCAGGCTCCTCATTTATGGTGC...  \n",
       "1      GGTGCATCCATTCTACACAGTGGAGTCCCATCAAGGTTCAGTGGCA...  \n",
       "2      CGCACGCTCATCTACGCCACAAGTGCTCGCTTTTCTGGGGTCCCTG...  \n",
       "3      TCCCCTGTGTTGGTCATCTATCAAGATGCCAAGCGGCCCTCAGGGA...  \n",
       "4      GGTACCAGCACAAACCTGGCCAGGCTCCCAGGCTCCTCGTCTATGC...  \n",
       "...                                                  ...  \n",
       "67988  ACTGTGATCTATGAGGATGATCACAGACCCTCTGGGGTCCCTGATC...  \n",
       "67989  GTCATCTATTATGATAGCGACCGACCCTCAGGGATCCCTGAGCGAT...  \n",
       "67990  AGAAACCAGGGAAACCCCCTAAGCTCCTGATCTACGATGCATCCAA...  \n",
       "67991  ACCGGCAGAAACCGGGACAGCCTCCTAAGCTGCTCATTTACTGGGC...  \n",
       "67992  CACTGTGATCTATGAGGATAAGCAAAGACCCTCTGGGGTCCCTGAT...  \n",
       "\n",
       "[67993 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rename_duplicate_column_names(df):\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique():\n",
    "        cols[cols[cols == dup].index.values] = [dup + \"_\" + str(i) if i != 0 else dup for i in range(sum(cols == dup))]\n",
    "    df.columns = cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7f880-f7f0-4a28-81fe-6a69032c012f",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bde319-f689-4451-b512-b0cfffc892f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "airr_api = Airr(reference_name=\"human\")\n",
    "oas_folder = \"OAS/data/OAS_paired\"\n",
    "leuko_file = \"OAS/data/D326651_Leuko_human_naive.csv.gz\"\n",
    "dekosky = \"OAS/data/DeKosky_paired\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af54a26b-f9bc-44bd-a198-97c5a2964ca2",
   "metadata": {},
   "source": [
    "# OAS Manifest as static metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "\n",
    "\n",
    "def spy_for_manifest(path):\n",
    "    if str(path).endswith(\".gz\"):\n",
    "        with gzip.open(path, \"rt\") as file:\n",
    "            header = list(file)[0]\n",
    "            if header.startswith('\"{'):\n",
    "                return True\n",
    "    else:\n",
    "        with open(path, \"r\") as file:\n",
    "            header = list(file)[0]\n",
    "            if header.startswith('\"{'):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# spy_for_manifest(\"OAS/data/DeKosky_paired/ERR4082227_paired.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b7a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest = pd.read_csv(\"OAS/data/oas_manifest.csv.gz\", compression=\"gzip\")\n",
    "\n",
    "manifest = manifest[\n",
    "    [\n",
    "        \"data_link\",\n",
    "        \"run\",\n",
    "        \"link\",\n",
    "        \"author\",\n",
    "        \"species\",\n",
    "        \"bsource\",\n",
    "        \"btype\",\n",
    "        \"longitudinal\",\n",
    "        \"age\",\n",
    "        \"disease\",\n",
    "        \"subject\",\n",
    "        \"vaccine\",\n",
    "        \"file_name\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "manifest.query('run == \"ERR4082303\"')\n",
    "manifest = manifest.query('species == \"human\"').drop_duplicates([\"run\"])\n",
    "run2manifest = manifest.set_index(\"run\", drop=False).to_dict(orient=\"index\")\n",
    "\"ERR4082303\" in run2manifest.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db751f",
   "metadata": {},
   "source": [
    "# STD load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a6a58-3936-48eb-8dc8-6315adb784b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR10358525\n",
      "SRR10358523\n",
      "SRR10358524\n",
      "CPU times: user 556 ms, sys: 112 ms, total: 668 ms\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Path('parquet-paired').mkdir(exist_ok=True)\n",
    "\n",
    "manifest = pd.read_csv(\"OAS/data/oas_manifest.csv.gz\", compression='gzip')\n",
    "\n",
    "paths = list(Path(oas_folder).glob('**/*.csv.gz')) \n",
    "# paths = [Path('OAS/data/DeKosky_paired/SRR10358525_paired.csv.gz')]\n",
    "\n",
    "# Run OAS misc Sequences through SADIE\n",
    "for path in paths:\n",
    "\n",
    "    # filename = path.stem.split('_paired')[0] \n",
    "    filename = path.stem.split('_')[0] \n",
    "    \n",
    "    if not filename.startswith('SRR'):\n",
    "        continue\n",
    "    \n",
    "    print(filename)\n",
    "    # Do not overwrite\n",
    "    # if Path(f'parquet-paired/{filename}.parquet').exists():\n",
    "    #     print('already exists', path)\n",
    "    #     continue\n",
    "    \n",
    "    if spy_for_manifest(path):\n",
    "        df = pd.read_csv(path, header=1, compression='gzip')\n",
    "    else:\n",
    "        df = pd.read_csv(path, compression='gzip')\n",
    "\n",
    "    df['sequence_id_heavy'] = df['sequence_id_heavy'].astype(str)\n",
    "    \n",
    "    # Heavy\n",
    "    sequences = [\n",
    "        SeqRecord(id=sequenec_id, name=sequenec_id, seq=Seq(sequence))\n",
    "        for sequenec_id, sequence in zip(df['sequence_id_heavy'], df['sequence_heavy'])\n",
    "    ]\n",
    "    with gzip.open(f\"OAS/data/fasta-heavy/{filename}.fasta.gz\", \"wt\") as output_handle:\n",
    "        SeqIO.write(sequences, output_handle, \"fasta\")\n",
    "    \n",
    "    # Light\n",
    "    sequences = [\n",
    "        SeqRecord(id=sequenec_id, name=sequenec_id, seq=Seq(sequence))\n",
    "        for sequenec_id, sequence in zip(df['sequence_id_light'], df['sequence_light'])\n",
    "    ]\n",
    "    with gzip.open(f\"OAS/data/fasta-light/{filename}.fasta.gz\", \"wt\") as output_handle:\n",
    "        SeqIO.write(sequences, output_handle, \"fasta\")\n",
    "        \n",
    "    # Paired\n",
    "    heavy_df = airr_api.run_fasta(f\"OAS/data/fasta-heavy/{filename}.fasta.gz\")\n",
    "    light_df = airr_api.run_fasta(f\"OAS/data/fasta-light/{filename}.fasta.gz\")\n",
    "    \n",
    "    heavy_df['tmp_id'] = heavy_df['sequence_id'].apply(lambda x: x.rsplit('_', 1)[0])\n",
    "    light_df['tmp_id'] = light_df['sequence_id'].apply(lambda x: x.rsplit('_', 1)[0])\n",
    "    \n",
    "    paired_df = pd.merge(heavy_df, light_df, how='outer', on='tmp_id', suffixes=('_heavy', '_light'))\n",
    "    paired_df = paired_df.drop(['tmp_id'], axis=1)\n",
    "    \n",
    "    # open manifest\n",
    "    run = filename.split('_')[0]\n",
    "    for k, v in run2manifest[run].items():\n",
    "        paired_df[k] = v\n",
    "\n",
    "    # merge with shared fields\n",
    "    # save new parquet\n",
    "    paired_df.to_parquet(f'parquet-paired/{filename}.parquet')\n",
    "    \n",
    "    del heavy_df\n",
    "    del light_df\n",
    "    del paired_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9ab7c",
   "metadata": {},
   "source": [
    "# Dekosky load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced22b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR1585265\n",
      "already exists data/DeKosky_paired/SRR1585265_joined_NoAlleles.csv\n",
      "SRR1585275\n",
      "already exists data/DeKosky_paired/SRR1585275_joined_NoAlleles.csv\n",
      "SRR1585248\n",
      "already exists data/DeKosky_paired/SRR1585248_joined_NoAlleles.csv\n",
      "SRR1585267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:22: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "/Users/tmsincomb/sadie/src/sadie/airr/igblast/igblast.py:957: DtypeWarning: Columns (37,38,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(tmpfile.name, sep=\"\\t\", dtype=IGBLAST_AIRR)  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR1585274\n",
      "SRR1585249\n",
      "CPU times: user 7.47 s, sys: 771 ms, total: 8.24 s\n",
      "Wall time: 4min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Path('parquet-paired').mkdir(exist_ok=True)\n",
    "\n",
    "manifest = pd.read_csv(\"OAS/data/oas_manifest.csv.gz\", compression='gzip')\n",
    "\n",
    "paths = list(Path(dekosky).glob('**/*.csv.gz'))\n",
    "# paths = [Path('OAS/data/DeKosky_paired/SRR10358525_paired.csv.gz')]\n",
    "\n",
    "# Run OAS misc Sequences through SADIE\n",
    "for path in paths:\n",
    "\n",
    "    # filename = path.stem.split('_paired')[0] \n",
    "    filename = path.stem.split('_')[0] \n",
    "    print(filename)\n",
    "    # Do not overwrite\n",
    "    if Path(f'parquet-paired/{filename}.parquet').exists():\n",
    "        print('already exists', path)\n",
    "        continue\n",
    "    \n",
    "    if spy_for_manifest(path):\n",
    "        df = pd.read_csv(path, header=1, compression='gzip')\n",
    "    else:\n",
    "        df = pd.read_csv(path, compression='gzip')\n",
    "\n",
    "    df = rename_duplicate_column_names(df)\n",
    "    df[\"sequence_id_heavy\"] = df[\"Sequence ID\"].astype(str)\n",
    "    df[\"sequence_id_light\"] = df[\"Sequence ID\"].astype(str)\n",
    "    df[\"sequence_heavy\"] = df[\"VDJ NT seq\"].astype(str)\n",
    "    df[\"sequence_light\"] = df[\"VDJ NT seq.1\"].astype(str)\n",
    "\n",
    "    df['sequence_id_heavy'] = df['sequence_id_heavy'].astype(str)\n",
    "    \n",
    "    # Heavy\n",
    "    sequences = [\n",
    "        SeqRecord(id=sequenec_id, name=sequenec_id, seq=Seq(sequence))\n",
    "        for sequenec_id, sequence in zip(df['sequence_id_heavy'], df['sequence_heavy'])\n",
    "    ]\n",
    "    with gzip.open(f\"OAS/data/fasta-heavy/{filename}.fasta.gz\", \"wt\") as output_handle:\n",
    "        SeqIO.write(sequences, output_handle, \"fasta\")\n",
    "    \n",
    "    # Light\n",
    "    sequences = [\n",
    "        SeqRecord(id=sequenec_id, name=sequenec_id, seq=Seq(sequence))\n",
    "        for sequenec_id, sequence in zip(df['sequence_id_light'], df['sequence_light'])\n",
    "    ]\n",
    "    with gzip.open(f\"OAS/data/fasta-light/{filename}.fasta.gz\", \"wt\") as output_handle:\n",
    "        SeqIO.write(sequences, output_handle, \"fasta\")\n",
    "        \n",
    "    # Paired\n",
    "    heavy_df = airr_api.run_fasta(f\"OAS/data/fasta-heavy/{filename}.fasta.gz\")\n",
    "    light_df = airr_api.run_fasta(f\"OAS/data/fasta-light/{filename}.fasta.gz\")\n",
    "    \n",
    "    heavy_df['tmp_id'] = heavy_df['sequence_id'].apply(lambda x: x.rsplit('_', 1)[0])\n",
    "    light_df['tmp_id'] = light_df['sequence_id'].apply(lambda x: x.rsplit('_', 1)[0])\n",
    "    \n",
    "    paired_df = pd.merge(heavy_df, light_df, how='outer', on='tmp_id', suffixes=('_heavy', '_light'))\n",
    "    paired_df = paired_df.drop(['tmp_id'], axis=1)\n",
    "    \n",
    "    # open manifest\n",
    "    # run = filename.split('_')[0]\n",
    "    # for k, v in run2manifest[run].items():\n",
    "    #     paired_df[k] = v\n",
    "    paired_df[\"run\"] = filename\n",
    "    paired_df[\"species\"] = \"human\"\n",
    "    paired_df[\"bsource\"] = \"PBMC\"\n",
    "    paired_df[\"author\"] = \"DeKosky\"\n",
    "    paired_df[\"btype\"] = \"Naive-B-Cells\"\n",
    "    paired_df[\"disease\"] = None\n",
    "    paired_df[\"file_name\"] = filename\n",
    "    \n",
    "    # merge with shared fields\n",
    "    # save new parquet\n",
    "    paired_df.to_parquet(f'parquet-paired/{filename}.parquet')\n",
    "    \n",
    "    del heavy_df\n",
    "    del light_df\n",
    "    del paired_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63320391-00f9-447b-a088-7167917c08bc",
   "metadata": {},
   "source": [
    "# Leuko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f6064-f8e9-49e8-a13d-46ba30c592c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D326651\n"
     ]
    }
   ],
   "source": [
    "leuko_file = \"OAS/data/D326651_Leuko_human_naive.csv.gz\"\n",
    "for path in [Path(leuko_file)]:\n",
    "    filename = path.stem.split(\"_\")[0]\n",
    "    print(filename)\n",
    "    df = pd.read_csv(path, compression=\"gzip\")\n",
    "\n",
    "    # Heavy\n",
    "    sequences = [\n",
    "        SeqRecord(\n",
    "            id=str(sequenec_id),\n",
    "            name=str(sequenec_id),\n",
    "            description=barcode,\n",
    "            seq=Seq(sequence),\n",
    "        )\n",
    "        for barcode, sequenec_id, sequence in zip(df[\"barcode\"], df[\"id_heavy\"], df[\"sequence_heavy\"])\n",
    "    ]\n",
    "    with gzip.open(f\"OAS/data/fasta-heavy/{filename}.fasta.gz\", \"wt\") as output_handle:\n",
    "        SeqIO.write(sequences, output_handle, \"fasta\")\n",
    "\n",
    "    # Light\n",
    "    sequences = [\n",
    "        SeqRecord(\n",
    "            id=str(sequenec_id),\n",
    "            name=str(sequenec_id),\n",
    "            description=barcode,\n",
    "            seq=Seq(sequence),\n",
    "        )\n",
    "        for barcode, sequenec_id, sequence in zip(df[\"barcode\"], df[\"id_light\"], df[\"sequence_light\"])\n",
    "    ]\n",
    "    with gzip.open(f\"OAS/data/fasta-light/{filename}.fasta.gz\", \"wt\") as output_handle:\n",
    "        SeqIO.write(sequences, output_handle, \"fasta\")\n",
    "\n",
    "    # Paired\n",
    "    heavy_df = airr_api.run_fasta(f\"OAS/data/fasta-heavy/{filename}.fasta.gz\")\n",
    "    light_df = airr_api.run_fasta(f\"OAS/data/fasta-light/{filename}.fasta.gz\")\n",
    "\n",
    "    heavy_df[\"tmp_id\"] = heavy_df[\"sequence_id\"].apply(lambda x: x.rsplit(\"_\", 1)[0])\n",
    "    light_df[\"tmp_id\"] = light_df[\"sequence_id\"].apply(lambda x: x.rsplit(\"_\", 1)[0])\n",
    "\n",
    "    paired_df = pd.merge(\n",
    "        heavy_df,\n",
    "        light_df,\n",
    "        how=\"outer\",\n",
    "        on=\"tmp_id\",\n",
    "        suffixes=(\"_heavy\", \"_light\"),\n",
    "    )\n",
    "    paired_df = paired_df.drop([\"tmp_id\"], axis=1)\n",
    "    paired_df[\"run\"] = \"D326651\"\n",
    "    paired_df[\"species\"] = \"human\"\n",
    "    paired_df[\"bsource\"] = \"PBMC\"\n",
    "    paired_df[\"author\"] = \"Jonathan Hurtado\"\n",
    "    paired_df[\"btype\"] = \"Naive-B-Cells\"\n",
    "    paired_df[\"disease\"] = None\n",
    "    paired_df[\"file_name\"] = \"D326651\"\n",
    "    # add manifest columns manually # TODO\n",
    "    paired_df.to_parquet(f\"parquet-paired/{filename}.parquet\")\n",
    "\n",
    "    del heavy_df\n",
    "    del light_df\n",
    "    del paired_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2df305-29b9-4811-a647-c56649658706",
   "metadata": {},
   "source": [
    "# Concat all parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3e11a-4fc0-403a-8339-cd7a5cb21bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def run_airr(chain):\n",
    "#     airr_api = Airr(reference_name='human')\n",
    "#     dfs = []\n",
    "#     for path in Path(f'OAS/data/fasta-{chain}').glob('*.fasta.gz'):\n",
    "#         df = airr_api.run_fasta(path)\n",
    "#         df.to_parquet(f'{path.stem}.parquet')\n",
    "#     return pd.concat(dfs)\n",
    "\n",
    "# heavy_df = run_airr('heavy')\n",
    "# light_df = run_airr('light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65acb25f-6636-4d08-8ba9-0e95e0ca6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paired_df = pd.merge(heavy_df, light_df, how='outer', on='sequence_id', suffixes=('_heavy', '_light'))\n",
    "# paired_df.to_parquet('all.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff503ab",
   "metadata": {},
   "source": [
    "# Make tailored manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR10358524\n",
      "ERR4082235\n",
      "1287148\n",
      "1287158\n",
      "1287151\n",
      "1279073\n",
      "1287150\n",
      "1287159\n",
      "1287149\n",
      "1287152\n",
      "1279068\n",
      "ERR4082303\n",
      "SRR10358523\n",
      "ERR4082227\n",
      "1287153\n",
      "ERR4082263\n",
      "1279075\n",
      "1279065\n",
      "1287156\n",
      "1287146\n",
      "ERR4082259\n",
      "ERR4082251\n",
      "1279074\n",
      "ERR4082267\n",
      "1287147\n",
      "1287157\n",
      "ERR4082283\n",
      "ERR4082243\n",
      "SRR10358525\n",
      "D326651\n",
      "1287155\n",
      "1287145\n",
      "1279076\n",
      "1279066\n",
      "ERR4082275\n",
      "ERR4082291\n",
      "1287144\n",
      "1287154\n",
      "1279067\n",
      "ERR4082299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Jaffe et al., 2022', 'King et al., 2020', 'Eccles et al., 2020'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "manifest = pd.read_csv(\"OAS/data/oas_manifest.csv.gz\", compression=\"gzip\")\n",
    "dfs = []\n",
    "for filename in glob.glob(\"parquet-paired/*.parquet\"):\n",
    "    print(runid)\n",
    "    runid = Path(filename).stem.split(\"_\")[0]\n",
    "    auth_subdf = manifest.query(f'species==\"human\" & run == \"{runid.upper()}\"').drop_duplicates(\"author\")\n",
    "    dfs.append(auth_subdf)\n",
    "df = pd.concat(dfs).reset_index().sort_values(\"run\")\n",
    "df.to_csv(\"OAS/data/oas_manifest_human_paired.csv.gz\", index=False, compression=\"gzip\")\n",
    "df.author.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sadie-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
